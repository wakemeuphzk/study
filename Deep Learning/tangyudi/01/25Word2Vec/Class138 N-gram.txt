N-gram模型

为了解决自由参数数目过多的问题，
引入了马尔科夫假设：随意一个词出现的概率只与它前面出现的有限的n个词有关。基于上述假设的统计语言模型被称为N-gram语言模型。

通常情况下，n的取值不能够太大，否则自由参数过多的问题依旧存在：
（1）当n=1时，即一个词的出现与它周围的词是独立，这种我们称为unigram，也就是一元语言模型，此时自由参数量级是词典大小V。
（2）当n=2时，即一个词的出现仅与它前面的一个词有关时，这种我们称为bigram，叫二元语言模型，也叫一阶马尔科夫链，此时自由参数数量级是V^2。
（3）当n=3时，即一个词的出现仅与它前面的两个词有关，称为trigram，叫三元语言模型，也叫二阶马尔科夫链，此时自由参数数量级是V^3。
一般情况下只使用上述取值，因为从上面可以看出，自由参数的数量级是n取值的指数倍。
从模型的效果来看，理论上n的取值越大，效果越好。但随着n取值的增加，效果提升的幅度是在下降的。同时还涉及到一个可靠性和可区别性的问题，参数越多，可区别性越好，但同时单个参数的实例变少从而降低了可靠性。

