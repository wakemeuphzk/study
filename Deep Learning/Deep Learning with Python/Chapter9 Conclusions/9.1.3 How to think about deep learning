如何看待深度学习？

在深度学习中，一切都是向量，即一切都是几何空间（geometric space）中的点（point）。

首先将模型输入（文本、图像等）和目标向量化（vectorize），即将其转换为初始输入向量空间和目标向量空间。
深度学习模型的每一层都对通过它的数据做一个简单的几何变换。模型中的层链共同形成了一个非常复杂的几何变换，它可以分解为一系列简单的几何变换。
这个复杂变换试图将输入空间映射到目标空间，每次映射一个点。这个变换由层的权重来参数化，权重根据模型当前表现进行迭代更新。
这种几何变换有一个关键性质，就是它必须是可微的（differentiable），这样我们才能通过梯度下降来学习其参数。
直观上来看，这意味着从输入到输出的几何变形必须是平滑且连续的，这是一个很重要的约束条件。

将这个复杂的几何变换应用于输入数据的过程，可以用三维的形式可视化——你可以想象一个人试图将一个纸球展平，这个皱巴巴的纸球就是模型初始输入数据的流形。
这个人对纸球做的每个动作都类似于某一层执行的简单几何变换。完整的展平动作系列就是整个模型所做的复杂变换。
深度学习模型就是用于解开高维数据复杂流形的数学机器。

这就是深度学习的神奇之处：将意义转换为向量，转换为几何空间，然后逐步学习将一个空间映射到另一个空间的复杂几何变换。
你需要的只是维度足够大的空间，以便捕捉到原始数据中能够找到的所有关系。
