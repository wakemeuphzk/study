2.文本相似度
   ⽤元素频率表⽰⽂本特征（位置固定）
   用余弦定理比较两个向量的相似度
   用NLTK进行Frequency 频率统计
   from nltk import FreqDist


3.文本分类
   TF-IDF:
   TF: Term Frequency, 衡量⼀个term在⽂档中出现得有多频繁。
TF(t) = (t出现在⽂档中的次数) / (⽂档中的term总数).
IDF: Inverse Document Frequency, 衡量⼀个term有多重要。
有些词出现的很多，但是明显不是很有卵⽤。⽐如’is'， ’the‘， ’and‘之类
的。
为了平衡，我们把罕见的词的重要性（weight）搞⾼，把常见词的重要性搞低。
IDF(t) = log_e(⽂档总数 / 含有t的⽂档总数).
TF-IDF = TF * IDF  频率*权重
   NLTK实现TF-IDF
   from nltk.text import TextCollection
   
   接下来怎么做？
   通过机器学习算法（SVM,LR,LSTM等）将vector转为label
