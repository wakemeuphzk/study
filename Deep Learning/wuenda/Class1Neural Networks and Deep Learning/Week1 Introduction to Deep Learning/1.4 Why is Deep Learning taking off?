为什么深度学习会兴起？

可以借助学习曲线：
在水平轴上画一个形状，在此绘制出所有任务的数据量，而在垂直轴上，画出机器学习算法的性能
当数据规模到一个点的时候，浅层的分类算法（eg:SVM、LR等）会趋于平缓，性能不再提高；
当规模再提升一个点的时候，训练一个小型的神经网络，可以提升部分性能，并趋于缓和；
训练一个中等规模的神经网络的时候，性能会表现更好一些，数据规模趋于缓和的点会继续往后移动；
当训练一个规模非常大的神经网络的时候，数据规模会很庞大，但性能会越来越好

如果你想要获得较高的性能体现，那么你有两个条件要完成，第一个是你需要训练一个规模足够大的神经网络，以发挥数据规模量巨大的优点，
另外你需要能画到轴的这个位置，所以你需要很多的数据。
要么训练一个更大的神经网络，要么投入更多的数据

神经网络方面的一个巨大突破是从sigmoid函数转换到一个修正线性单元ReLU函数：使梯度下降算法运行地更快

我们通过改变算法，使得代码运行的更快，这也使得我们能够训练规模更大的神经网络，或者是多端口的网络



