逻辑回归的代价函数


假设函数，含sigmoid形式

损失函数L,在单个训练样本上定义
通过这个称为L的损失函数，来衡量预测输出值和实际值有多接近。一般我们用预测值和实际值的平方差或者它们平方差的一半，
但是通常在逻辑回归中我们不这么做，因为当我们在学习逻辑回归参数的时候，会发现我们的优化目标不是凸优化，只能找到多个局部最优值，
梯度下降法很可能找不到全局最优值，虽然平方差是一个不错的损失函数，但是我们在逻辑回归模型中会定义另外一个损失函数。

代价函数J，所有训练样本上的定义

可以将逻辑回归当作一个很小的神经网络



