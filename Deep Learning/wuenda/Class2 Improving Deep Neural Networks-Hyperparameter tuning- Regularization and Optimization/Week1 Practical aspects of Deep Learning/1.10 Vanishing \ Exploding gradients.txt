梯度消失\梯度爆炸

也就是你训练神经网络的时候，导数或坡度有时会变得非常大，或者非常小，甚至于以指数方式变大（梯度爆炸）或变小（梯度消失），这加大了训练的难度。
