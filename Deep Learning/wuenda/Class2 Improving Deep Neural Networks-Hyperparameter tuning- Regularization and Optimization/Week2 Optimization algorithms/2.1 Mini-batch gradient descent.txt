Mini-batch 梯度下降

向量化能够让你有效地对所有m个样本进行计算，允许你处理整个训练集，而无需某个明确的公式.
如果m很大的话，处理速度仍然缓慢。比如说，如果m是500万或5000万或者更大的一个数.
你可以把训练集分割为小一点的子集训练，这些子集被取名为mini-batch，假设每一个子集中只有1000个样本.

batch梯度下降法指的是我们之前讲过的梯度下降法算法，就是同时处理整个训练集.
