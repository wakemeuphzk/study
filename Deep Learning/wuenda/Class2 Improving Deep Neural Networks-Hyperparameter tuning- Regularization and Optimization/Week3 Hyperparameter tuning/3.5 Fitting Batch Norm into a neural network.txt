将 Batch Norm 拟合进神经网络

Batch归一化通常和训练集的mini-batch一起使用。

所以总结一下，因为Batch归一化超过了此层z[l]的均值，这个参数b[l]没有意义，所以，你必须去掉它，由代替，这是个控制参数，会影响转移或偏置条件
