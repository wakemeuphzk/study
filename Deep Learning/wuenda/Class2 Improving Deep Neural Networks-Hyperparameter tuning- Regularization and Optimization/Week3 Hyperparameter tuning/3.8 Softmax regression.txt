Softmax回归

整个计算过程，从计算幂到得出临时变量t，再归一化，我们可以将此概括为一个Softmax激活函数.

之前，我们的激活函数都是接受单行数值输入，例如Sigmoid和ReLu激活函数，输入一个实数，输出一个实数。
Softmax激活函数的特殊之处在于，因为需要将所有可能的输出归一化，就需要输入一个向量，最后输出一个向量。

Softmax分类器在没有隐藏层的情况下能够做到的事情，用线性决策边界来分类，
当然更深的神经网络会有，然后是一些隐藏单元，以及更多隐藏单元等等，你就可以学习更复杂的非线性决策边界，来区分多种不同分类。
