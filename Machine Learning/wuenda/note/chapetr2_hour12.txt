线性回归的梯度下降

线性回归模型：假设函数与代价函数
梯度下降算法：寻找使代价函数最小的参数

Bactch Gradient Descent “批量梯度下降”，指的是在梯度下降的每一步中，我们都用到了所有的训练样本。
在梯度下降中，在计算微分求导项时，我们需要进行求和运算，所以，在每一个单独的梯度下降中，我们最终都要计算这样一个东西，这个项需要对所有$m$个训练样本求和。
